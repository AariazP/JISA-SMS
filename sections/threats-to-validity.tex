\section{Threats to Validity}
\label{sec:threat-validity}
Four categories of threats to validity are identified, along with the mitigation strategies employed.

\subsection{Selection Bias}
Seven measures were implemented to mitigate selection bias. First, the SMS followed established guidelines~\cite{Runeson2009,Kitchenham2010}, including GQM and PICOC frameworks. Second, five major databases were queried. Third, synonyms were included for all key terms to ensure broad coverage. Fourth, search strings were iteratively refined through pilot searches. Fifth, a hybrid strategy combining database search with snowballing increased coverage. Sixth, alert systems (Endnote, Mendeley, Google Scholar) monitored for newly published studies. Seventh, three quality indices (CVI, SCI, IRRQ) provided complementary assessment perspectives. The CVI and IRRQ indices carry inherent subjectivity; this was mitigated through collaborative evaluation by an odd number of independent evaluators ($K \geq 3$).

\subsection{Classification Errors}
Studies were classified according to the topics defined during planning, corresponding to CBV technologies, IT domains, education, research, and outreach. Multi-topic classification was permitted when a study's scope spanned multiple areas. All classifications underwent peer review by an odd number of evaluators to reduce individual bias.

\subsection{Data Extraction Inaccuracy}
The SMS-Builder software~\cite{candela2020smsbuilder} was used for structured data extraction, minimizing manual processing errors. Peer review was conducted on extracted data following the recommendations of Kitchenham and Charters~\cite{Kitchenham2010}.

\subsection{Search Protocol Errors}
The search protocol was executed under peer review: one evaluator implemented the protocol while a second independently verified the process. SMS-Builder was used throughout to reduce manual data handling and ensure process consistency.
